{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parser.parse_args()\n",
    "print(opt) \n",
    "if opt.notLog:\n",
    "    log_stuff = False\n",
    "    print(\"No logging is being done!!\")\n",
    "\n",
    "if ntbk and not log_stuff:\n",
    "    print(\"OP folder won't be created as we are in jupyter notebook and logging is off\")\n",
    "elif log_stuff:\n",
    "    if opt.opFolder != '':\n",
    "        print(\"Overriding the name of output folder from: \",op_folder,\"to: \",opt.opFolder+run_tStamp, \" Not recommended!! \")\n",
    "        op_folder = opt.opFolder+run_tStamp\n",
    "    if opt.resumeFldr != \"\":\n",
    "        if not os.path.exists(opt.resumeFldr):\n",
    "            print(\"Given output folder does not exist! So will create new\")\n",
    "        else:\n",
    "            op_folder = opt.resumeFldr\n",
    "            print(\"Things would be resumed from the folder: \", opt.resumeFldr)\n",
    "    if not os.path.exists(op_folder):\n",
    "        os.makedirs(op_folder)\n",
    "    else:\n",
    "        if opt.resumeFldr == \"\":\n",
    "            print(\"op_folder: \",op_folder,\" alrady exist.. things may be ovrwritten\")\n",
    "\n",
    "log_file = os.path.join(op_folder, \"LOG_\"+f_name+run_tStamp+\".log\")\n",
    "\n",
    "#Apparently for logging to work I need to restart the code\n",
    "import logging\n",
    "if log_stuff:\n",
    "    print(\"doing logging: \",log_file)\n",
    "    r = logging.basicConfig(filename=log_file,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.INFO)\n",
    "#logging.basicConfig(filename='example.log',  level=logging.DEBUG)\n",
    "def plog(*args):\n",
    "    if log_stuff:\n",
    "        logging.info(\" \".join([str(t) for t in args]))\n",
    "    else:\n",
    "        print(*args)\n",
    "\n",
    "plog(\"Arguments are: \", opt)\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "if opt.noCuda:\n",
    "    if cuda:\n",
    "        print(\"\\nCuda won't be used, though a graphics card is present!! (Not advisable)\")\n",
    "\n",
    "#Now some module specific imports:\n",
    "#sys.path.append(\"../\")\n",
    "#from freezed.diverseClkFaces import *\n",
    "\n",
    "def param_count(ntwk):\n",
    "    return \"{:.3f}M\".format(np.sum([np.product(p.shape) for p in ntwk.parameters()])/1000000)\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from freezed.diverseClkFaces import *\n",
    "#img = None\n",
    "class clock_datatset(Dataset):\n",
    "    def __init__(self, root=\"/home/aknirala/data/clocks/\", transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #global img\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()[0]\n",
    "        with open(os.path.join(self.root,\n",
    "                               str(idx//1000),\n",
    "                               str(idx%1000000) \n",
    "                               +\".pkl\"), \"rb\") as f:\n",
    "            #img = pickle.load(f)\n",
    "            sample = pickle.load(f).transpose([1, 2, 0])#Image.fromarray(np.uint8(img.transpose([1, 2, 0])*255))\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "class diverse_clock(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return 1000000 #It is practically infinite; 1B\n",
    "    def __getitem__(self, idx):\n",
    "        sample, h_m = getRandomClock() #To avoid error\n",
    "        sample = sample.copy()\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, h_m\n",
    "\n",
    "class paired_clocks(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.h_eye = torch.eye(12)\n",
    "        self.m_eye = torch.eye(60)\n",
    "    def __len__(self):\n",
    "        return 1000000 #It is practically infinite\n",
    "    def __getitem__(self, idx):\n",
    "        #But many might get the same state!!!\n",
    "        frm = (idx%5)*100\n",
    "        till = frm + idx%100\n",
    "        st0 = np.random.get_state()\n",
    "        for i in range(frm, till):\n",
    "            st0[1][i] += 5\n",
    "        np.random.set_state(st0)\n",
    "        sample, h_m = getRandomClock(randSeed=-1)\n",
    "        h2 = np.random.randint(12)\n",
    "        m2 = np.random.randint(60)\n",
    "        sample1 = sample.copy()\n",
    "        #\n",
    "        np.random.set_state(st0)\n",
    "        sample, h_m2 = getRandomClock(randSeed=-1, h=h2, m=m2)\n",
    "        sample2 = sample.copy()\n",
    "        #\n",
    "        #Now, let's encode h and m\n",
    "        H = self.h_eye[[h_m[0], h_m2[0]]]\n",
    "        M = self.m_eye[[h_m[1], h_m2[1]]]\n",
    "        #\n",
    "        if self.transform:\n",
    "            sample1 = self.transform(sample1)\n",
    "            sample2 = self.transform(sample2)\n",
    "            sample = torch.stack([sample1, sample2])\n",
    "            return sample, H, M\n",
    "        else:\n",
    "            return [sample1, sample2], H, M\n",
    "\n",
    "class same_style_clocks(Dataset):\n",
    "    def __init__(self, randSeed = 2, transform=None):\n",
    "        self.transform = transform\n",
    "        self.randSeed = randSeed\n",
    "        self.h_eye = torch.eye(12)\n",
    "        self.m_eye = torch.eye(60)\n",
    "    def __len__(self):\n",
    "        return 1000000 #It is practically infinite\n",
    "    def __getitem__(self, idx):\n",
    "        idx720 = idx%720\n",
    "        sample, h_m = getRandomClock(randSeed=self.randSeed, h = idx720//60, m = idx720%12)\n",
    "        sample = sample.copy()\n",
    "        H = self.h_eye[h_m[0]]\n",
    "        M = self.m_eye[h_m[1]]\n",
    "        #\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            return sample, H, M\n",
    "        else:\n",
    "            return sample, H, M\n",
    "\n",
    "if opt.dataset == 'lsun':\n",
    "    dataset = dset.LSUN(root=opt.dataroot, classes=['bedroom_train'],\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(opt.fineSize),\n",
    "                                transforms.CenterCrop(opt.fineSize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "elif opt.dataset == 'CelebA': #it is CelebA\n",
    "    dataset = dset.ImageFolder(root=opt.dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(opt.fineSize),\n",
    "                               transforms.CenterCrop(opt.fineSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "elif opt.dataset == 'clocks': #it is CelebA\n",
    "    dataset = clock_datatset(root=opt.dataroot,\n",
    "                             transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Resize(opt.fineSize),\n",
    "                                transforms.CenterCrop(opt.fineSize),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "elif opt.dataset == 'diverse_clocks':\n",
    "    dataset = diverse_clock(transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Resize(opt.fineSize),\n",
    "                                transforms.CenterCrop(opt.fineSize),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "elif opt.dataset == 'paired_clocks':\n",
    "    dataset = paired_clocks(transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Resize(64),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "else:\n",
    "    plog(\"No dataset for opt.dataset: \",opt.dataset)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
    "                                            shuffle=True, num_workers=int(opt.workers))\n",
    "plog(\"Len of iterations per epochs: \",len(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gan_37]",
   "language": "python",
   "name": "conda-env-gan_37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
